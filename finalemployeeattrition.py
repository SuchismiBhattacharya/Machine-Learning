# -*- coding: utf-8 -*-
"""FinalEmployeeAttrition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Hq_aB0qb9y7oYd7j7LxkAhuhAQK4rtRe
"""

#imports
import pandas as pd
import numpy as np
from sklearn import model_selection
from numpy import percentile
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn import linear_model
from sklearn import metrics
from sklearn import ensemble
from sklearn import tree
from sklearn import naive_bayes
from sklearn.feature_selection import RFECV
import random
from sklearn import neighbors
from sklearn.metrics import roc_curve, auc
from sklearn.feature_selection import VarianceThreshold

#we have to predict if an employee will get attrited or not
employeeDataset = pd.read_csv("EmployeeAttrition.csv")

employeeDataset.isnull().sum()   # no null values
employeeDataset.dtypes   #data types

employeeDataset.info()

#now after seeing the no of colums i realized that i needed to speed things up so at first i started pre-processing the
#columns with discrete values


#columns with discrete values 

employeeDataset.info()
"""
Attrition                   1470 non-null object
BusinessTravel              1470 non-null int64
Department                  1470 non-null int64
Education                   1470 non-null int64
EducationField              1470 non-null object
EnvironmentSatisfaction     1470 non-null int64
Gender                      1470 non-null object
JobInvolvement              1470 non-null int64
JobLevel                    1470 non-null int64
JobRole                     1470 non-null object
JobSatisfaction             1470 non-null int64
MaritalStatus               1470 non-null object
Over18                      1470 non-null object
OverTime                    1470 non-null object
PerformanceRating           1470 non-null int64
RelationshipSatisfaction    1470 non-null int64
StockOptionLevel            1470 non-null int64
WorkLifeBalance             1470 non-null int64
"""

employeeDataset["Attrition"].replace({"Yes":1,"No":0} , inplace = True)
employeeDataset["Attrition"].value_counts()

def changeDiscrete(seriesName):
  valuesInSeries = list(set(employeeDataset[seriesName].values))
  dictTemp = {} 
  for i in range(len(valuesInSeries)):
    dictTemp[valuesInSeries[i]] = i
  
  employeeDataset[seriesName].replace(dictTemp , inplace = True)
  
discreteSeriesNames = [
    "Attrition",
    "BusinessTravel",
    "Department",
    "Education",
    "EducationField",
    "EnvironmentSatisfaction",
    "Gender",
    "JobInvolvement",
    "JobLevel",
    "JobRole",
    "JobSatisfaction",
    "MaritalStatus",
    "Over18",
    "OverTime",
    "PerformanceRating",
    "RelationshipSatisfaction",
    "StockOptionLevel",
    "WorkLifeBalance"
]

for i in discreteSeriesNames[1:]:
  changeDiscrete(i)

tempDataset = pd.read_csv("EmployeeAttrition.csv")

#splitting X and Y fields


X = employeeDataset.drop("Attrition" , axis = 1)
y = employeeDataset["Attrition"]

#X.info()
#(y.value_counts())
#print(tempDataset.Attrition.value_counts())

#y.replace(tempDict , inplace = True)

print(y.value_counts())   # { "No" , 0 , "Yes" , 1 }




print(X["BusinessTravel"].value_counts())
print(tempDataset["BusinessTravel"].value_counts())
print(X["Department"].value_counts())
print(tempDataset["Department"].value_counts())
print(X["Education"].value_counts())
print(tempDataset["Education"].value_counts())
print(X["EducationField"].value_counts())
print(tempDataset["EducationField"].value_counts())
print(X["EnvironmentSatisfaction"].value_counts())
print(tempDataset["EnvironmentSatisfaction"].value_counts())
print(X["Gender"].value_counts())
print(tempDataset["Gender"].value_counts())
print(X["JobInvolvement"].value_counts())
print(tempDataset["JobInvolvement"].value_counts())
print(X["JobLevel"].value_counts())
print(tempDataset["JobLevel"].value_counts())
print(X["JobRole"].value_counts())
print(tempDataset["JobRole"].value_counts())
print(X["JobSatisfaction"].value_counts())
print(tempDataset["JobSatisfaction"].value_counts())
print(X["MaritalStatus"].value_counts())
print(tempDataset["MaritalStatus"].value_counts())
print(X["Over18"].value_counts())
print(tempDataset["Over18"].value_counts())
print(X["OverTime"].value_counts())
print(tempDataset["OverTime"].value_counts())
print(X["PerformanceRating"].value_counts())
print(tempDataset["PerformanceRating"].value_counts())
print(X["RelationshipSatisfaction"].value_counts())
print(tempDataset["RelationshipSatisfaction"].value_counts())
print(X["StockOptionLevel"].value_counts())
print(tempDataset["StockOptionLevel"].value_counts())
print(X["WorkLifeBalance"].value_counts())
print(tempDataset["WorkLifeBalance"].value_counts())
print(tempDataset["StandardHours"].value_counts())

#by analysing we determine the apperently redundant cols

#EmployeeCount    #all values are 1
#EmployeeNumber  #kind of a roll no , I think it's not important
#Over18   #all values in dataset is Yes
#StandardHours  #all values in dataset is 80


#new X

def newX(list_,Xnew):
  for i in list_:
    Xnew = Xnew.drop(i , axis = 1)
  return Xnew
arr_ = ["EmployeeCount" , "EmployeeNumber" , "Over18" , "StandardHours"]

Xnew = newX(arr_ , X)

Xnew.info()

#we seperate some of the data for testing in later stages

XnewTrain,Xtest,ytrain,ytest = model_selection.train_test_split(Xnew,y,test_size=.2,random_state=42)

#checking the correlation amongst rows

employeeDataset.corr()["Attrition"]

#FIVE NUMBER STATISTICS

#Function for checking the continuous columns


def printValueCounts(listOfCols):
  #print(listOfCols)
  for i in listOfCols:
    print(i)
    print(len(set(XnewTrain[i])))

#printValueCounts((XnewTrain.columns))
#XnewTrain["Age"].value_counts()

discreteCols = [                  
    "BusinessTravel",
    "Department",
    "Education",
    "EducationField",
    "EnvironmentSatisfaction",
    "Gender",
    "JobInvolvement",
    "JobLevel",
    "JobRole",
    "JobSatisfaction",
    "MaritalStatus",
    "OverTime",
    "PerformanceRating",
    "RelationshipSatisfaction",
    "StockOptionLevel",
    "WorkLifeBalance"
]

continuousCols = []

for i in list(XnewTrain.columns):
  if i not in discreteCols:
    continuousCols.append(i)
print(len(continuousCols))

fig,axes = plt.subplots(nrows = 14,ncols = 1, figsize = (5,50))  #for creating a 50x5 area for plotting thirty-five images
axes1 = axes.flatten()   #the 14 locations of plotting
for index,col in enumerate(continuousCols):
  sns.boxplot(y = col, data = XnewTrain, ax = axes1[index])
plt.tight_layout()


#Monthly income, YearsAtCompany, YearsSinceLastPromotion, TotalWorkingYears have many upper outliers

fig,axes = plt.subplots(nrows = 16,ncols = 1, figsize = (5,55))  #for creating a 50x5 area for plotting thirty-five images
axes1 = axes.flatten()   #the 14 locations of plotting
for index,col in enumerate(discreteCols):
  sns.countplot(y = col, data = XnewTrain, hue = y, ax = axes1[index])
plt.tight_layout()

def findIQR(npArray):
  sortedArr = sorted(npArray)
  lowerMedianArray = []
  greaterMedianArray = []
  if len(sortedArr) % 2 == 0:
    lowerArray = sortedArr[:int(len(npArray)/2)]
    upperArray = sortedArr[int(len(npArray)/2):]
  else:
    lowerArray = sortedArr[:int(len(npArray)/2)]
    upperArray = sortedArr[int(len(npArray)/2) + 1:]
  #print(lowerArray, upperArray)
  return [np.median(np.array(lowerArray)) , np.median(np.array(upperArray))]
    

def fivePointStatistics(dataFrame,continuousCols):
  for i in continuousCols:
    print("====Five point statistics of columns====",i)
    print("Median(Q2) = ",np.median(dataFrame[i]))
    lowerMedian , upperMedian = findIQR(dataFrame[i])
    print("Lower Median(Q1) = ",lowerMedian)
    print("Upper Median(Q3) = ",upperMedian)
    IQR = upperMedian  - lowerMedian
    
    upperOutlier = upperMedian + 1.5*IQR
    lowerOutlier = lowerMedian - 1.5*IQR
    
    high = max([v for v in dataFrame[i] if v < upperOutlier])
    low = min([v for v in dataFrame[i] if v > lowerOutlier])
    print("high = ",high)
    print("low = ",low)
    
    
    upperOutlierPoints = []
    lowerOutlierPoints = []
    
    #notToChange = ["Monthly income", "YearsAtCompany", "YearsSinceLastPromotion", "TotalWorkingYears"]
    
    upperOutlierPoints = [v for v in dataFrame[i] if v > upperOutlier]
    lowerOutlierPoints = [v for v in dataFrame[i] if v < lowerOutlier]
    
    print("No of lower outliers =",len(lowerOutlierPoints))
    print("No of upper outliers =",len(upperOutlierPoints))
    
    
    #tempMean = np.mean(dataFrame[i])
    
    """
    if i not in notToChange:    #except above mentioned cols , change all other outliers to their means
      for j in range(len(dataFrame[i])):    
        if XnewTrain[i][j] > upperOutlier or XnewTrain[i][j] < lowerOutlier:
          XnewTrain[i][j] = tempMean
    
    
    """

fivePointStatistics(XnewTrain, continuousCols)

print(len(ytrain))    #1176
print(len(XnewTrain)) #1176

fig,axes = plt.subplots(figsize = (20,20))
sns.heatmap(XnewTrain.corr(), annot = True, linewidths = .25,ax = axes)

empDataset = employeeDataset.copy()

fig,axes = plt.subplots(nrows = 5,ncols = 3, figsize = (20,20))  #for creating a 5x3 area for plotting 4 images
axes1 = axes.flatten()   #the 4 locations of plotting





for index,col in enumerate(["Age","DistanceFromHome","NumCompaniesWorked","TotalWorkingYears",
                            "HourlyRate","DailyRate","MonthlyRate","MonthlyIncome","PercentSalaryHike","YearsAtCompany",
                           "YearsInCurrentRole","YearsWithCurrManager","YearsSinceLastPromotion"]):
  #sns.countplot(x = col, data = empDataset, ax = axes1[index])
  sns.distplot(empDataset[col], ax = axes1[index], hist = False)
plt.tight_layout()


##observation :
# the age is almost normally distributed 
# hourly rate, daily rate, monthly rate and monthly income give no special information
# rest of the cols are skewed and need to be normalised

fig,axes = plt.subplots(nrows = 7,ncols = 2, figsize = (10,40))  #for creating a 5x3 area for plotting 4 images
axes1 = axes.flatten()   #the 4 locations of plotting





for index,col in enumerate(["Gender","Education","EducationField","MaritalStatus",
                            "RelationshipSatisfaction","WorkLifeBalance","BusinessTravel","EnvironmentSatisfaction",
                            "JobInvolvement","JobSatisfaction","OverTime",
                           "PerformanceRating","Department","JobRole"]):
  graph = sns.countplot(x = col, data = pd.read_csv("EmployeeAttrition.csv"), ax = axes1[index])
  for item in graph.get_xticklabels():
    item.set_rotation(90)
  for p in graph.patches:
        graph.annotate('{}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+5))
    
    
#observations:
#More than 50% of Male population.
#More than 37% is having a level 3 degree and 27% is having a level 4 degree.
#Almost 75% of the employees come from Life Sciences and Medical background.
#45% of the employees are marrried whereas 22% of them are divorced.
#More than 30% of the employees have a High or Very High Relationship Satisfaction.
#More than 60% of the employees feel they have a level 3 work life balance.
#More than 70% of the employees Travel rarely for work.
#30% of the employees have a level 3 and level 4 environment satisfaction each.
#Almost 59% of the employees think they have a level 3 job involvement at work.
#Again in Job Satisifaction we see that 30% employees have a high and a level 4 job satisfaction each.
#More than 70% of the people seem to be working over time.
#85% of the employees have an excellent performance rating.
#More than half of the employees work for the R&D department.
#Majority of the employees work as Sales Executives, Research Scientists and Laboratory Technicians.

fig,axes = plt.subplots(nrows = 7,ncols = 2, figsize = (13,36))  #for creating a 5x3 area for plotting 4 images
axes1 = axes.flatten()

for index,col in enumerate(["Age","DistanceFromHome","NumCompaniesWorked","TotalWorkingYears",
                            "HourlyRate","DailyRate","MonthlyRate","MonthlyIncome","PercentSalaryHike","YearsAtCompany",
                           "YearsInCurrentRole","YearsWithCurrManager","YearsSinceLastPromotion"]):
  for i in [1,0]:
    subset = empDataset[empDataset["Attrition" ] == i]
    # Draw the density plot
    sns.distplot(subset[col], hist = False, kde = True,
                   kde_kws = {'linewidth': 3},
                   label = i,ax = axes1[index])
     
    # Plot formatting
  plt.xlabel(col)
  plt.ylabel('Density')
  
  
#Observations :


#1.Younger employees within 25-35 years have a higher attrition rate.
#2.We see a lower attrition rate when the Distance from home is within 10 kms. The attrition rate increase post 10kms.
#3.The attrition rate tends to be higher with employees who have worked with 5 to 7 companies.
#4.Attrition rate seems to be extremely high amongst employees who have a total working experience between 0 to 7 years 
#approximately.
#5.No specific trend observed except for Daily rate where we see two modes. The attrition is highest near 400 whereas 
#the attrition is lowest near 1200.
#6.We observe a peak in attrition rate at a monthly income approx. 2500.
#7.We also see a peak in attrition rate when the employee is with the company for 0-2 years approx.
#8.From the two modes observed in “Years in Current Role” plot we can say that the attrition rate is higher when the 
#employee is in the same role for 0-2 years or 6 years approx.
#9.Also, From the two modes observed in “Years with current manager” plot we can say that employee also tends to leave 
#if he is with the same manager for less than 1.5 years or 6 years approximately.
#10.Years in current role and years with current manager tend to have the same effect on the attrition

fig,axes = plt.subplots(nrows = 7,ncols = 2, figsize = (13,36))

def getBarsAndHeight(dataFrame,colName):
  classes = dataFrame[colName].unique()
  yPos = np.arange(len(classes))
  
  count = [0 for i in range(len(classes))]
  temp = 0
  for i in range(1470):
    for j in range(len(classes)):
      if dataFrame["Attrition"][i] == "Yes" and dataFrame[colName][i] == classes[j]:
        count[j] += 1
  
  for i in range(len(classes)):
    count[i] /= len(dataFrame[dataFrame[colName] == classes[i]])
    count[i] *= 100
  
  return (yPos,count,classes)


for index,col in enumerate(["Gender","Education","EducationField","MaritalStatus",
                            "RelationshipSatisfaction","WorkLifeBalance","BusinessTravel","EnvironmentSatisfaction",
                            "JobInvolvement","JobSatisfaction","OverTime",
                           "PerformanceRating","Department","JobRole"]):
  yPos, heights, classes = getBarsAndHeight(pd.read_csv("EmployeeAttrition.csv"),col)
  plt.subplot(7,2,index + 1)
  plt.bar(yPos,heights)
  plt.title(col)
  plt.xticks(yPos, classes)
  plt.xticks(rotation = 90)
  plt.ylabel("Attrition_Rate")
  
  
#Observations :

#1.Attrition Rate is slightly more in Males as compared to Females.
#2.18% attrition rate is observed amongst employees have level 1 education.
#3.Attrition rate is very high amongst employees from HR, Marketing and Technical backgrounds.
#4.As expected, the attrition rate is very high amongst employees who have a bad work life balance.
#5.Attrition rate is higher amongst people who travel frequently.
#6.Its also higher amongst employees who have a low environment satisfaction, low job involvement and low job satisfaction.
#7.The attrition rate is almost 30% amongst employees who work over time.
#8.Sales department have the highest attrition at 20%
#9.Sales Representatives have the highest attrition at 40%.

###Removing skewness

#skewed cols are : 
#"DistanceFromHome","NumCompaniesWorked","TotalWorkingYears","PercentSalaryHike",
#"YearsAtCompany","YearsInCurrentRole","YearsWithCurrManager","YearsSinceLastPromotion"

#using log and sigmoid to do something about the skewedness

###USING LOG

skewRemDataset = empDataset.copy()

skewRemDataset[["DistanceFromHome","NumCompaniesWorked","TotalWorkingYears","PercentSalaryHike",
               "YearsAtCompany","YearsInCurrentRole","YearsWithCurrManager","YearsSinceLastPromotion"]] = np.log(skewRemDataset[["DistanceFromHome","NumCompaniesWorked","TotalWorkingYears","PercentSalaryHike",
               "YearsAtCompany","YearsInCurrentRole","YearsWithCurrManager","YearsSinceLastPromotion"]] + 1)


#using the +1 to remove any 0s from the data, as log0 = Nan
#empDataset["PerformanceRating"].value_counts()

fig,axes = plt.subplots(nrows = 4,ncols = 2, figsize = (11,11))  #for creating a 5x3 area for plotting 4 images
axes1 = axes.flatten()   #the 4 locations of plotting





for index,col in enumerate(["DistanceFromHome","NumCompaniesWorked","TotalWorkingYears",
                            "PercentSalaryHike","YearsAtCompany",
                           "YearsInCurrentRole","YearsWithCurrManager","YearsSinceLastPromotion"]):
  sns.kdeplot(skewRemDataset[col], ax = axes1[index])
plt.tight_layout()

####USING SIGMOID


skewRemDataset1 = empDataset.copy()

def sigmoid(cols,dataFrame):
  
  for i in cols:
    dataFrame[i] = 1/(1 + np.exp(dataFrame[i])**-1)
  return dataFrame
  
  


skewRemDataset1 = sigmoid(["DistanceFromHome","NumCompaniesWorked","TotalWorkingYears","PercentSalaryHike",
               "YearsAtCompany","YearsInCurrentRole","YearsWithCurrManager","YearsSinceLastPromotion"], skewRemDataset1)

fig,axes = plt.subplots(nrows = 4,ncols = 2, figsize = (11,11))  #for creating a 5x3 area for plotting 4 images
axes1 = axes.flatten()   #the 4 locations of plotting





for index,col in enumerate(["DistanceFromHome","NumCompaniesWorked","TotalWorkingYears",
                            "PercentSalaryHike","YearsAtCompany",
                           "YearsInCurrentRole","YearsWithCurrManager","YearsSinceLastPromotion"]):
  sns.kdeplot(skewRemDataset1[col], ax = axes1[index])
plt.tight_layout()

####AS the LOG gives better result so we go with the log version and discard the sigmoid

#Again chacking for the boxplot to see outliers

#FIVE NUMBER STATISTICS

#Function for checking the continuous columns


def printValueCounts(listOfCols):
  #print(listOfCols)
  for i in listOfCols:
    print(i)
    print(len(set(XnewTrain[i])))

#printValueCounts((XnewTrain.columns))
#XnewTrain["Age"].value_counts()

discreteCols = [                  
    "BusinessTravel",
    "Department",
    "Education",
    "EducationField",
    "EnvironmentSatisfaction",
    "Gender",
    "JobInvolvement",
    "JobLevel",
    "JobRole",
    "JobSatisfaction",
    "MaritalStatus",
    "OverTime",
    "PerformanceRating",
    "RelationshipSatisfaction",
    "StockOptionLevel",
    "WorkLifeBalance"
]

continuousCols = []

for i in list(XnewTrain.columns):
  if i not in discreteCols:
    continuousCols.append(i)
print(len(continuousCols))

fig,axes = plt.subplots(nrows = 14,ncols = 1, figsize = (5,50))  #for creating a 50x5 area for plotting thirty-five images
axes1 = axes.flatten()   #the 14 locations of plotting
for index,col in enumerate(continuousCols):
  sns.boxplot(y = col, data = skewRemDataset, ax = axes1[index])
plt.tight_layout()


#we see that most of the outliers are removed except the MonthlyIncome

def findIQR(npArray):
  sortedArr = sorted(npArray)
  lowerMedianArray = []
  greaterMedianArray = []
  if len(sortedArr) % 2 == 0:
    lowerArray = sortedArr[:int(len(npArray)/2)]
    upperArray = sortedArr[int(len(npArray)/2):]
  else:
    lowerArray = sortedArr[:int(len(npArray)/2)]
    upperArray = sortedArr[int(len(npArray)/2) + 1:]
  #print(lowerArray, upperArray)
  return [np.median(np.array(lowerArray)) , np.median(np.array(upperArray))]
    

def fivePointStatistics(dataFrame,continuousCols):
  for i in continuousCols:
    print("====Five point statistics of columns====",i)
    print("Median(Q2) = ",np.median(dataFrame[i]))
    lowerMedian , upperMedian = findIQR(dataFrame[i])
    print("Lower Median(Q1) = ",lowerMedian)
    print("Upper Median(Q3) = ",upperMedian)
    IQR = upperMedian  - lowerMedian
    
    upperOutlier = upperMedian + 1.5*IQR
    lowerOutlier = lowerMedian - 1.5*IQR
    
    high = max([v for v in dataFrame[i] if v < upperOutlier])
    low = min([v for v in dataFrame[i] if v > lowerOutlier])
    print("high = ",high)
    print("low = ",low)
    
    
    upperOutlierPoints = []
    lowerOutlierPoints = []
    
    #notToChange = ["Monthly income", "YearsAtCompany", "YearsSinceLastPromotion", "TotalWorkingYears"]
    
    upperOutlierPoints = [v for v in dataFrame[i] if v > upperOutlier]
    lowerOutlierPoints = [v for v in dataFrame[i] if v < lowerOutlier]
    
    print("No of lower outliers =",len(lowerOutlierPoints))
    print("No of upper outliers =",len(upperOutlierPoints))
    
    return upperOutlier
    #tempMean = np.mean(dataFrame[i])
    
    """
    if i not in notToChange:    #except above mentioned cols , change all other outliers to their means
      for j in range(len(dataFrame[i])):    
        if XnewTrain[i][j] > upperOutlier or XnewTrain[i][j] < lowerOutlier:
          XnewTrain[i][j] = tempMean
    
    
    """

upperOutlier = fivePointStatistics(skewRemDataset, ["MonthlyIncome"])

#now finding the outliers of MonthlyIncome
#still too many values to change, so we keep it as it is

#FEATURE SELECTION

#skewRemDataset 
#At first we remove the EmployeeCount, Over18 and StandardHours

#skewRemDataset = skewRemDataset.drop(["EmployeeCount", "Over18", "StandardHours"], axis = 1)
skewRemDataset.corr()
#finding the highly corelated independent variables

setOfRemovableVars = []

for i in range(len(list(skewRemDataset.columns))):
  for j in range(len(list(skewRemDataset.columns))):
    if abs(skewRemDataset.corr()[list(skewRemDataset.columns)[i]][j]) >= 0.7 and i != j and list(skewRemDataset.columns)[i] != "Attrition" and list(skewRemDataset.columns)[j] != "Attrition":
      print(list(skewRemDataset.columns)[i],list(skewRemDataset.columns)[j],skewRemDataset.corr()[list(skewRemDataset.columns)[i]][j])
      setOfRemovableVars.append(list(skewRemDataset.columns)[i])
      setOfRemovableVars.append(list(skewRemDataset.columns)[j])
setOfRemovableVars = list(set(setOfRemovableVars))

print(setOfRemovableVars)

#finding corelation of setOfRemovableVars with Attrition

for i in range(len(setOfRemovableVars)):
  print("Attrition -",setOfRemovableVars[i],skewRemDataset.corr()["Attrition"][list(skewRemDataset.columns).index(setOfRemovableVars[i])])

#One hot encoding of the discrete cols

dC = ["Gender","Education","EducationField","MaritalStatus","RelationshipSatisfaction","WorkLifeBalance","BusinessTravel",
      "EnvironmentSatisfaction","JobInvolvement","JobSatisfaction","OverTime","Department","JobRole"] 
#removing performance rating

XoneHotEnc = pd.get_dummies(skewRemDataset[dC], columns = dC)

XoneHotEnc.head()

#taking the cols of discrete values who have max and min attrition_rate from the above graphs as they hold the max
#importance and removing the performance rating column as it is somewhat same in attrition rate for 0 and 1(from graph)
"""
    "BusinessTravel", Travel_freq(1), Non_trave;(2) 
    "Department", Sales(1), R & D(0)
    "Education", 1(0) , 5(4)
    "EducationField", Other(3) , HR(5)
    "EnvironmentSatisfaction", 1(0), 3(2)
    "Gender", - Male(0)
    "JobInvolvement", 1(0), 4(3)
    "JobRole", SalesRep(3) , Manager(6)
    "JobSatisfaction", 1(0), 4(3)
    "MaritalStatus", Single(1), Divorced(0)
    "OverTime", Yes(1)
    "RelationshipSatisfaction", 1(0) , 2(1)
    "WorkLifeBalance" 1(0),3(2)
    """
XoneHotEnc = XoneHotEnc[["BusinessTravel_1","BusinessTravel_2","Department_1","Department_0","Education_0",
                       "Education_4","EducationField_3","EducationField_5","EnvironmentSatisfaction_0",
                       "EnvironmentSatisfaction_2","Gender_0","JobInvolvement_0","JobInvolvement_3",
                       "JobRole_3","JobRole_6","JobSatisfaction_0","JobSatisfaction_3","MaritalStatus_1",
                       "MaritalStatus_0","OverTime_1","RelationshipSatisfaction_0",
                       "RelationshipSatisfaction_1","WorkLifeBalance_0","WorkLifeBalance_2"]].copy()

XoneHotEnc.info()   #relavant discrete cols according to the barplots

#NOW for selection of the relevant continuous cols


dCols = ["Gender","Education","EducationField","MaritalStatus","RelationshipSatisfaction","WorkLifeBalance","BusinessTravel",
      "EnvironmentSatisfaction","JobInvolvement","JobSatisfaction","OverTime","Department","JobRole","JobLevel"] 

continuousDataSet = skewRemDataset.drop(dCols, axis = 1).copy()
setOfRemovableVarsCon  = []
for i in range(len(list(continuousDataSet.columns))):
  for j in range(len(list(continuousDataSet.columns))):
    if abs(continuousDataSet.corr()[list(continuousDataSet.columns)[i]][j]) >= 0.7 and i != j and list(continuousDataSet.columns)[i] != "Attrition" and list(continuousDataSet.columns)[j] != "Attrition":
      print(list(continuousDataSet.columns)[i],list(continuousDataSet.columns)[j],continuousDataSet.corr()[list(continuousDataSet.columns)[i]][j])
      setOfRemovableVarsCon.append(list(continuousDataSet.columns)[i])
      setOfRemovableVarsCon.append(list(continuousDataSet.columns)[j])
setOfRemovableVarsCon = list(set(setOfRemovableVarsCon))

print(setOfRemovableVarsCon)

#finding corelation of setOfRemovableVars with Attrition

for i in range(len(setOfRemovableVarsCon)):
  print("Attrition -",setOfRemovableVarsCon[i],continuousDataSet.corr()["Attrition"][list(continuousDataSet.columns).index(setOfRemovableVarsCon[i])])
                                                                                                                                   
#Removing PerformanceRating,YearsInCurrentRole,YearsWithCurrManager as their corelation amongst other cols is high and
#coralation with Attrition is relatively low

newContCols = continuousDataSet.drop(["PerformanceRating","YearsInCurrentRole","YearsWithCurrManager","Over18","EmployeeNumber","EmployeeCount","StandardHours"], axis = 1).copy()

newDatasetAfterTakingSigCols = pd.concat([XoneHotEnc,newContCols],axis = 1)
newDatasetAfterTakingSigCols.info()

y = newDatasetAfterTakingSigCols["Attrition"]

X = newDatasetAfterTakingSigCols.drop(["Attrition"], axis = 1).copy()

#for checking the relavant characteristics of the five models

def modelstats1(Xtrain,Xtest,ytrain,ytest):
    stats=[]
    modelnames=["LR","DecisionTree","KNN","NB","RF"]
    models=list()
    models.append(linear_model.LogisticRegression())
    models.append(tree.DecisionTreeClassifier())
    models.append(neighbors.KNeighborsClassifier())
    models.append(naive_bayes.BernoulliNB())
    models.append(ensemble.RandomForestClassifier(n_estimators = 60,max_depth = 13))
    for name,model in zip(modelnames,models):
        if name=="KNN":
            k=[l for l in range(5,17,2)]
            grid={"n_neighbors":k}
            grid_obj = model_selection.GridSearchCV(estimator=model,param_grid=grid,scoring="f1")
            grid_fit =grid_obj.fit(Xtrain,ytrain)
            model = grid_fit.best_estimator_
            model.fit(Xtrain,ytrain)
            name=name+"("+str(grid_fit.best_params_["n_neighbors"])+")"
            print(grid_fit.best_params_)
        else:
            model.fit(Xtrain,ytrain)
        trainprediction=model.predict(Xtrain)
        testprediction=model.predict(Xtest)
        scores=list()
        scores.append(name+"-train")
        scores.append(metrics.accuracy_score(ytrain,trainprediction))
        scores.append(metrics.precision_score(ytrain,trainprediction))
        scores.append(metrics.recall_score(ytrain,trainprediction))
        scores.append(metrics.roc_auc_score(ytrain,trainprediction))
        stats.append(scores)
        scores=list()
        scores.append(name+"-test")
        scores.append(metrics.accuracy_score(ytest,testprediction))
        scores.append(metrics.precision_score(ytest,testprediction))
        scores.append(metrics.recall_score(ytest,testprediction))
        scores.append(metrics.roc_auc_score(ytest,testprediction))
        stats.append(scores)
    
    colnames=["MODELNAME","ACCURACY","PRECISION","RECALL","AUC"]
    return pd.DataFrame(stats,columns=colnames)
Xtrain,Xtest,ytrain,ytest = model_selection.train_test_split(X,y,test_size=.2,random_state=42)
modelstats1(Xtrain,Xtest,ytrain,ytest)

#Also checking the model performances without one hot encoding

discreteCols = [                  
    "BusinessTravel",
    "Department",
    "Education",
    "EducationField",
    "EnvironmentSatisfaction",
    "Gender",
    "JobInvolvement",
    "JobLevel",
    "JobRole",
    "JobSatisfaction",
    "MaritalStatus",
    "OverTime",
    "PerformanceRating",
    "RelationshipSatisfaction",
    "WorkLifeBalance",
]
valsWithoutOneHotEn = skewRemDataset[discreteCols].copy()
valsWithoutOneHotEn = pd.concat([valsWithoutOneHotEn, newContCols], axis = 1)
#valsWithoutOneHotEn.info()
X = valsWithoutOneHotEn.drop(["Attrition"],axis = 1)
y = valsWithoutOneHotEn["Attrition"]
Xtrain1,Xtest1,ytrain1,ytest1 = model_selection.train_test_split(X,y,test_size=.2,random_state=42)
modelstats1(Xtrain1,Xtest1,ytrain1,ytest1)

#we see that we get slightly better auc for one hot encoded dataset

#So we chose the one hot encoded cols dataset and we chose naive bayes, logistic regression, random forest

#We tune the hyper parameters of the random forest

#N_estimators
#max_depth
#min_sample_split
#min_samples_leaf
#max_features

def estimationForNEstimators(x_train,y_train,x_test,y_test):
  n_estimators = [1, 2, 4, 8, 16, 32, 64, 100, 200]
  train_results = []
  test_results = []
  for estimator in n_estimators:
    rf = ensemble.RandomForestClassifier(n_estimators=estimator, n_jobs=-1)
    rf.fit(x_train, y_train)
    train_pred = rf.predict(x_train)
    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)
    roc_auc = auc(false_positive_rate, true_positive_rate)
    train_results.append(roc_auc)
    y_pred = rf.predict(x_test)
    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)
    roc_auc = auc(false_positive_rate, true_positive_rate)
    test_results.append(roc_auc)
  from matplotlib.legend_handler import HandlerLine2D
  line1, = plt.plot(n_estimators, train_results, 'b', label='Train AUC')
  line2, = plt.plot(n_estimators, test_results, 'r', label='Test AUC')
  plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})
  plt.ylabel('AUC score')
  plt.xlabel('n_estimators')
  plt.show()



y = newDatasetAfterTakingSigCols["Attrition"]

X = newDatasetAfterTakingSigCols.drop(["Attrition"], axis = 1).copy()
Xtrain,Xtest,ytrain,ytest = model_selection.train_test_split(X,y,test_size=.2,random_state=42)

estimationForNEstimators(Xtrain,ytrain,Xtest,ytest)


#So we select N_estimators = 60 from the graph, because after that the auc almost nover changes

#for max_depth

def max_depth_fun(x_train, y_train, x_test, y_test):
  max_depths = np.linspace(1, 32, 32, endpoint=True)
  train_results = []
  test_results = []
  for max_depth in max_depths:
    rf = ensemble.RandomForestClassifier(max_depth=max_depth, n_jobs=-1)
    rf.fit(x_train, y_train)
    train_pred = rf.predict(x_train)
    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)
    roc_auc = auc(false_positive_rate, true_positive_rate)
    train_results.append(roc_auc)
    y_pred = rf.predict(x_test)
    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)
    roc_auc = auc(false_positive_rate, true_positive_rate)
    test_results.append(roc_auc)
  from matplotlib.legend_handler import HandlerLine2D
  line1, = plt.plot(max_depths, train_results, 'b', label='Train AUC')
  line2, = plt.plot(max_depths, test_results, 'r', label='Test AUC')
  plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})
  plt.ylabel('AUC score')
  plt.xlabel('Tree depth')
  plt.show()

  
max_depth_fun(Xtrain,ytrain,Xtest,ytest)
#Selecting the max_depth = 13

#for min_sample_split


def min_samples_splits_fun(x_train, y_train, x_test, y_test):
  min_samples_splits = np.linspace(0.1, 1.0, 100, endpoint=True)
  train_results = []
  test_results = []
  for min_samples_split in min_samples_splits:
    rf = ensemble.RandomForestClassifier(min_samples_split=min_samples_split)
    rf.fit(x_train, y_train)
    train_pred = rf.predict(x_train)
    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)
    roc_auc = auc(false_positive_rate, true_positive_rate)
    train_results.append(roc_auc)
    y_pred = rf.predict(x_test)
    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)
    roc_auc = auc(false_positive_rate, true_positive_rate)
    test_results.append(roc_auc)
  from matplotlib.legend_handler import HandlerLine2D
  line1, = plt.plot(min_samples_splits, train_results, 'b', label='Train AUC')
  line2, = plt.plot(min_samples_splits, test_results, 'r', label='Test AUC')
  plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})
  plt.ylabel('AUC score')
  plt.xlabel('min samples split')
  plt.show()
  
min_samples_splits_fun(Xtrain, ytrain, Xtest, ytest)


#### Not sure

def min_samples_leafs_fun(x_train, y_train, x_test, y_test):
  min_samples_leafs = np.linspace(0.01, 0.5, 70, endpoint=True)
  train_results = []
  test_results = []
  for min_samples_leaf in min_samples_leafs:
    rf = ensemble.RandomForestClassifier(min_samples_leaf=min_samples_leaf)
    rf.fit(x_train, y_train)
    train_pred = rf.predict(x_train)
    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)
    roc_auc = auc(false_positive_rate, true_positive_rate)
    train_results.append(roc_auc)
    y_pred = rf.predict(x_test)
    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)
    roc_auc = auc(false_positive_rate, true_positive_rate)
    test_results.append(roc_auc)
  from matplotlib.legend_handler import HandlerLine2D
  line1, = plt.plot(min_samples_leafs, train_results, 'b', label='Train AUC')
  line2, = plt.plot(min_samples_leafs, test_results, 'r', label='Test AUC')
  plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})
  plt.ylabel('AUC score')
  plt.xlabel('min samples leaf')
  plt.show()
  
  
  
min_samples_leafs_fun(Xtrain, ytrain, Xtest, ytest)


#not sure

def max_features_fun(x_train,y_train,x_test,y_test):
  max_features = list(range(1,x_train.shape[1]))
  train_results = []
  test_results = []
  for max_feature in max_features:
    rf = ensemble.RandomForestClassifier(max_features=max_feature)
    rf.fit(x_train, y_train)
    train_pred = rf.predict(x_train)
    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)
    roc_auc = auc(false_positive_rate, true_positive_rate)
    train_results.append(roc_auc)
    y_pred = rf.predict(x_test)
    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)
    roc_auc = auc(false_positive_rate, true_positive_rate)
    test_results.append(roc_auc)
  from matplotlib.legend_handler import HandlerLine2D
  line1, = plt.plot(max_features, train_results, 'b', label='Train AUC')
  line2, = plt.plot(max_features, test_results, 'r', label='Test AUC')
  plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})
  plt.ylabel('AUC score')
  plt.xlabel('max features')
  plt.show()
  
max_features_fun(Xtrain,ytrain,Xtest,ytest)

#not sure but lets test 6
#didn't get good result with 6 so we decided not to use it

modelstats1(Xtrain,Xtest,ytrain,ytest)

#we see that after hyperparameter the auc of random forest classifier increases by 2-4 %

###Generating the roc curves for the three models
# split into train/test sets
# fit a model
model = linear_model.LogisticRegression()
model.fit(Xtrain, ytrain)
# predict probabilities
probs = model.predict_proba(Xtest)
# keep probabilities for the positive outcome only
probs = probs[:, 1]
# calculate AUC
auc = metrics.roc_auc_score(ytest, probs)
print('AUC: %.3f' % auc)
# calculate roc curve
fpr, tpr, thresholds = metrics.roc_curve(ytest, probs)
# plot no skill
plt.plot([0, 1], [0, 1], linestyle='--')
# plot the roc curve for the model
plt.plot(fpr, tpr, marker='.')
# show the plot
plt.show()

###Generating the roc curves for the three models
# split into train/test sets
# fit a model
model = naive_bayes.BernoulliNB()
model.fit(Xtrain, ytrain)
# predict probabilities
probs = model.predict_proba(Xtest)
# keep probabilities for the positive outcome only
probs = probs[:, 1]
# calculate AUC
auc = metrics.roc_auc_score(ytest, probs)
print('AUC: %.3f' % auc)
# calculate roc curve
fpr, tpr, thresholds = metrics.roc_curve(ytest, probs)
# plot no skill
plt.plot([0, 1], [0, 1], linestyle='--')
# plot the roc curve for the model
plt.plot(fpr, tpr, marker='.')
# show the plot
plt.show()

model = ensemble.RandomForestClassifier(n_estimators = 60,max_depth = 13)

model.fit(Xtrain, ytrain)
# predict probabilities
probs = model.predict_proba(Xtest)
# keep probabilities for the positive outcome only
probs = probs[:, 1]
# calculate AUC
auc = metrics.roc_auc_score(ytest, probs)
print('AUC: %.3f' % auc)
# calculate roc curve
fpr, tpr, thresholds = metrics.roc_curve(ytest, probs)
# plot no skill
plt.plot([0, 1], [0, 1], linestyle='--')
# plot the roc curve for the model
plt.plot(fpr, tpr, marker='.')
# show the plot
plt.show()

###I AM NOT SURE ABOUT THE LAST THREE GRAPHS >>>>>>>>>>>>>>
### JUST FINISh THE WHOLE DOCUMENTATION AND KEEP THREE PLACES EMPTY 
#### #### ####
####REST OF THE PART IS FINAL CODE AND YOU CAN USE IT BOTH FOR DOCUMENTATION AND PPT